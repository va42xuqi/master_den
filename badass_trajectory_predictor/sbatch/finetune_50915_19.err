GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
wandb: Currently logged in as: luffnis (luffnis1). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in ./wandb/run-20240801_015935-27uw2rwm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vel_1l_linear_NBA_train_50_100_nba_fine_tune
wandb: â­ï¸ View project at https://wandb.ai/luffnis1/lightning_logs
wandb: ğŸš€ View run at https://wandb.ai/luffnis1/lightning_logs/runs/27uw2rwm
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]

  | Name   | Type   | Params
----------------------------------
0 | linear | Linear | 80.2 K
----------------------------------
80.2 K    Trainable params
0         Non-trainable params
80.2 K    Total params
0.321     Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Metric val/ADE improved. New best score: 2.187
Epoch 0, global step 95: 'val/ADE' reached 2.18735 (best 2.18735), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/nba/vel_1l_linear_nba_fine_tune-v1.ckpt' as top 1
Epoch 1, global step 190: 'val/ADE' was not in top 1
Epoch 2, global step 285: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.024 >= min_delta = 0.0. New best score: 2.163
Epoch 3, global step 380: 'val/ADE' reached 2.16344 (best 2.16344), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/nba/vel_1l_linear_nba_fine_tune-v1.ckpt' as top 1
Epoch 4, global step 475: 'val/ADE' was not in top 1
Epoch 5, global step 570: 'val/ADE' was not in top 1
Epoch 6, global step 665: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.002 >= min_delta = 0.0. New best score: 2.161
Epoch 7, global step 760: 'val/ADE' reached 2.16143 (best 2.16143), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/nba/vel_1l_linear_nba_fine_tune-v1.ckpt' as top 1
Epoch 8, global step 855: 'val/ADE' was not in top 1
Epoch 9, global step 950: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.006 >= min_delta = 0.0. New best score: 2.156
Epoch 10, global step 1045: 'val/ADE' reached 2.15571 (best 2.15571), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/nba/vel_1l_linear_nba_fine_tune-v1.ckpt' as top 1
Epoch 11, global step 1140: 'val/ADE' was not in top 1
Epoch 12, global step 1235: 'val/ADE' was not in top 1
Epoch 13, global step 1330: 'val/ADE' was not in top 1
Epoch 14, global step 1425: 'val/ADE' was not in top 1
Epoch 15, global step 1520: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.002 >= min_delta = 0.0. New best score: 2.154
Epoch 16, global step 1615: 'val/ADE' reached 2.15407 (best 2.15407), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/nba/vel_1l_linear_nba_fine_tune-v1.ckpt' as top 1
Epoch 17, global step 1710: 'val/ADE' was not in top 1
Epoch 18, global step 1805: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.019 >= min_delta = 0.0. New best score: 2.135
Epoch 19, global step 1900: 'val/ADE' reached 2.13540 (best 2.13540), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/nba/vel_1l_linear_nba_fine_tune-v1.ckpt' as top 1
Epoch 20, global step 1995: 'val/ADE' was not in top 1
Epoch 21, global step 2090: 'val/ADE' was not in top 1
Epoch 22, global step 2185: 'val/ADE' was not in top 1
Epoch 23, global step 2280: 'val/ADE' was not in top 1
Epoch 24, global step 2375: 'val/ADE' was not in top 1
Epoch 25, global step 2470: 'val/ADE' was not in top 1
Epoch 26, global step 2565: 'val/ADE' was not in top 1
Epoch 27, global step 2660: 'val/ADE' was not in top 1
Epoch 28, global step 2755: 'val/ADE' was not in top 1
Epoch 29, global step 2850: 'val/ADE' was not in top 1
Epoch 30, global step 2945: 'val/ADE' was not in top 1
Epoch 31, global step 3040: 'val/ADE' was not in top 1
Epoch 32, global step 3135: 'val/ADE' was not in top 1
Epoch 33, global step 3230: 'val/ADE' was not in top 1
Epoch 34, global step 3325: 'val/ADE' was not in top 1
Epoch 35, global step 3420: 'val/ADE' was not in top 1
Epoch 36, global step 3515: 'val/ADE' was not in top 1
Epoch 37, global step 3610: 'val/ADE' was not in top 1
Epoch 38, global step 3705: 'val/ADE' was not in top 1
Monitored metric val/ADE did not improve in the last 20 records. Best score: 2.135. Signaling Trainer to stop.
Epoch 39, global step 3800: 'val/ADE' was not in top 1
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]
SLURM auto-requeueing enabled. Setting signal handlers.
wandb: - 5.544 MB of 5.544 MB uploadedwandb: \ 5.544 MB of 5.575 MB uploadedwandb: | 5.575 MB of 5.575 MB uploadedwandb: 
wandb: Run history:
wandb:   CPU energy consumption (kWh) â–„â–„â–‡â–…â–„â–„â–â–…â–…â–…â–„â–„â–…â–„â–â–„â–„â–„â–ˆâ–„â–ˆâ–â–„â–„â–…â–„â–„â–„â–„â–â–„â–„â–…â–„â–„â–„â–„â–â–…â–„
wandb:   GPU energy consumption (kWh) â–„â–„â–ˆâ–…â–…â–„â–â–„â–…â–„â–…â–…â–„â–„â–â–…â–„â–„â–‡â–„â–ˆâ–â–„â–„â–„â–„â–„â–„â–„â–â–…â–…â–„â–„â–„â–„â–„â–â–„â–„
wandb:   RAM energy consumption (kWh) â–„â–„â–ˆâ–„â–„â–„â–â–„â–„â–„â–…â–„â–„â–„â–â–„â–„â–„â–‡â–„â–ˆâ–â–„â–„â–„â–„â–„â–„â–„â–â–„â–…â–„â–„â–„â–„â–„â–â–„â–ƒ
wandb: Total energy consumption (kWh) â–„â–„â–ˆâ–…â–…â–„â–â–„â–…â–…â–…â–„â–…â–„â–â–„â–„â–„â–ˆâ–„â–ˆâ–â–„â–„â–…â–„â–„â–„â–„â–â–„â–…â–…â–„â–„â–„â–„â–â–…â–„
wandb:                          epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:               train/loss_epoch â–…â–„â–â–„â–‚â–ƒâ–…â–ƒâ–…â–ƒâ–…â–‚â–„â–ƒâ–ƒâ–…â–ƒâ–â–‚â–„â–‚â–†â–…â–ˆâ–„â–ƒâ–ˆâ–‚â–‚â–ƒâ–ƒâ–…â–‚â–…â–ƒâ–â–ƒâ–‚â–ƒâ–ƒ
wandb:                train/loss_step â–‚â–ƒâ–„â–‡â–â–‡â–…â–‚â–ˆâ–ƒâ–„â–„â–„â–ƒâ–‚â–…â–„â–‚â–…â–ƒâ–‡â–…â–†â–†â–â–…â–ƒâ–ƒâ–…â–‚â–†â–…â–‚â–…â–ƒâ–…â–…â–ƒâ–ƒâ–ƒ
wandb:            trainer/global_step â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–â–â–â–„â–„â–„â–„â–…â–…â–…â–â–â–â–â–â–â–â–â–â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–â–â–â–â–
wandb:                  val/ADE_epoch â–…â–…â–‡â–ƒâ–‡â–†â–…â–ƒâ–ƒâ–‡â–‚â–†â–…â–…â–‡â–ƒâ–‚â–†â–‚â–â–‡â–†â–‡â–ƒâ–†â–…â–‡â–ƒâ–†â–„â–†â–ƒâ–‚â–…â–„â–ˆâ–†â–…â–ƒâ–…
wandb:                   val/ADE_step â–‡â–‡â–†â–…â–‡â–‡â–ˆâ–ƒâ–†â–‚â–†â–‚â–„â–‚â–‡â–ƒâ–ƒâ–†â–ƒâ–†â–…â–‡â–†â–…â–…â–†â–…â–†â–…â–ˆâ–„â–†â–„â–†â–ƒâ–†â–â–…â–â–…
wandb:                  val/FDE_epoch â–…â–„â–…â–„â–…â–…â–†â–ƒâ–„â–†â–„â–„â–…â–„â–ˆâ–†â–ƒâ–‡â–ƒâ–ƒâ–…â–†â–…â–„â–ˆâ–‡â–†â–„â–…â–‡â–†â–â–â–…â–„â–ˆâ–„â–ƒâ–‚â–†
wandb:                   val/FDE_step â–‡â–‡â–†â–…â–‡â–‡â–ˆâ–ƒâ–†â–‚â–†â–‚â–ƒâ–‚â–…â–„â–ƒâ–‡â–ƒâ–‡â–„â–‡â–…â–…â–†â–‡â–†â–†â–†â–‡â–„â–‡â–…â–†â–ƒâ–†â–‚â–†â–â–…
wandb:               val/NL_ADE_epoch â–†â–ƒâ–„â–…â–…â–…â–„â–ƒâ–â–…â–ƒâ–†â–†â–„â–ƒâ–‚â–‚â–„â–â–„â–„â–ˆâ–„â–ƒâ–„â–ƒâ–‚â–ƒâ–„â–‚â–„â–‚â–…â–„â–†â–†â–…â–…â–ƒâ–†
wandb:                val/NL_ADE_step â–…â–…â–„â–„â–…â–†â–†â–„â–…â–ƒâ–…â–‚â–…â–‚â–„â–‚â–â–‡â–‚â–ˆâ–…â–ˆâ–„â–„â–„â–…â–ƒâ–…â–„â–†â–„â–†â–„â–…â–ƒâ–†â–ƒâ–„â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:   CPU energy consumption (kWh) 0.0
wandb:   GPU energy consumption (kWh) 1e-05
wandb:   RAM energy consumption (kWh) 0.0
wandb: Total energy consumption (kWh) 2e-05
wandb:                          epoch 40
wandb:               train/loss_epoch 2.00314
wandb:                train/loss_step 1.95126
wandb:            trainer/global_step 3800
wandb:                  val/ADE_epoch 2.19063
wandb:                   val/ADE_step 2.2834
wandb:                  val/FDE_epoch 4.73118
wandb:                   val/FDE_step 4.82812
wandb:               val/NL_ADE_epoch 2.64622
wandb:                val/NL_ADE_step 2.84887
wandb: 
wandb: ğŸš€ View run vel_1l_linear_NBA_train_50_100_nba_fine_tune at: https://wandb.ai/luffnis1/lightning_logs/runs/27uw2rwm
wandb: â­ï¸ View project at: https://wandb.ai/luffnis1/lightning_logs
wandb: Synced 6 W&B file(s), 0 media file(s), 6 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240801_015935-27uw2rwm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
