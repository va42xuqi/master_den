GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
wandb: Currently logged in as: luffnis (luffnis1). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in ./wandb/run-20240801_003527-z5amb67l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run uni_bitnet_NBA_train_50_100_nba_fine_tune
wandb: â­ï¸ View project at https://wandb.ai/luffnis1/lightning_logs
wandb: ğŸš€ View run at https://wandb.ai/luffnis1/lightning_logs/runs/z5amb67l
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]

  | Name      | Type       | Params
-----------------------------------------
0 | linear    | Linear     | 26.9 K
1 | x_encoder | GPTLike    | 4.8 M 
2 | y_encoder | GPTLike    | 4.8 M 
3 | x_cnn     | CNNEncoder | 6.4 K 
4 | y_cnn     | CNNEncoder | 6.4 K 
5 | x_fc_out  | Linear     | 25.7 K
6 | y_fc_out  | Linear     | 25.7 K
7 | dropout   | Dropout    | 0     
-----------------------------------------
9.6 M     Trainable params
0         Non-trainable params
9.6 M     Total params
38.498    Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Metric val/ADE improved. New best score: 2.026
Epoch 0, global step 378: 'val/ADE' reached 2.02617 (best 2.02617), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/nba/uni_bitnet_nba_fine_tune-v1.ckpt' as top 1
Epoch 1, global step 756: 'val/ADE' was not in top 1
Epoch 2, global step 1134: 'val/ADE' was not in top 1
Epoch 3, global step 1512: 'val/ADE' was not in top 1
Epoch 4, global step 1890: 'val/ADE' was not in top 1
Epoch 5, global step 2268: 'val/ADE' was not in top 1
Epoch 6, global step 2646: 'val/ADE' was not in top 1
Epoch 7, global step 3024: 'val/ADE' was not in top 1
Epoch 8, global step 3402: 'val/ADE' was not in top 1
Epoch 9, global step 3780: 'val/ADE' was not in top 1
Epoch 10, global step 4158: 'val/ADE' was not in top 1
Epoch 11, global step 4536: 'val/ADE' was not in top 1
Epoch 12, global step 4914: 'val/ADE' was not in top 1
Epoch 13, global step 5292: 'val/ADE' was not in top 1
Epoch 14, global step 5670: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.010 >= min_delta = 0.0. New best score: 2.016
Epoch 15, global step 6048: 'val/ADE' reached 2.01604 (best 2.01604), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/nba/uni_bitnet_nba_fine_tune-v1.ckpt' as top 1
Epoch 16, global step 6426: 'val/ADE' was not in top 1
Epoch 17, global step 6804: 'val/ADE' was not in top 1
Epoch 18, global step 7182: 'val/ADE' was not in top 1
Epoch 19, global step 7560: 'val/ADE' was not in top 1
Epoch 20, global step 7938: 'val/ADE' was not in top 1
Epoch 21, global step 8316: 'val/ADE' was not in top 1
Epoch 22, global step 8694: 'val/ADE' was not in top 1
Epoch 23, global step 9072: 'val/ADE' was not in top 1
Epoch 24, global step 9450: 'val/ADE' was not in top 1
Epoch 25, global step 9828: 'val/ADE' was not in top 1
Epoch 26, global step 10206: 'val/ADE' was not in top 1
Epoch 27, global step 10584: 'val/ADE' was not in top 1
Epoch 28, global step 10962: 'val/ADE' was not in top 1
Epoch 29, global step 11340: 'val/ADE' was not in top 1
Epoch 30, global step 11718: 'val/ADE' was not in top 1
Epoch 31, global step 12096: 'val/ADE' was not in top 1
Epoch 32, global step 12474: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.018 >= min_delta = 0.0. New best score: 1.998
Epoch 33, global step 12852: 'val/ADE' reached 1.99759 (best 1.99759), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/nba/uni_bitnet_nba_fine_tune-v1.ckpt' as top 1
Epoch 34, global step 13230: 'val/ADE' was not in top 1
Epoch 35, global step 13608: 'val/ADE' was not in top 1
Epoch 36, global step 13986: 'val/ADE' was not in top 1
Epoch 37, global step 14364: 'val/ADE' was not in top 1
Epoch 38, global step 14742: 'val/ADE' was not in top 1
Epoch 39, global step 15120: 'val/ADE' was not in top 1
Epoch 40, global step 15498: 'val/ADE' was not in top 1
Epoch 41, global step 15876: 'val/ADE' was not in top 1
Epoch 42, global step 16254: 'val/ADE' was not in top 1
Epoch 43, global step 16632: 'val/ADE' was not in top 1
Epoch 44, global step 17010: 'val/ADE' was not in top 1
Epoch 45, global step 17388: 'val/ADE' was not in top 1
Epoch 46, global step 17766: 'val/ADE' was not in top 1
Epoch 47, global step 18144: 'val/ADE' was not in top 1
Epoch 48, global step 18522: 'val/ADE' was not in top 1
Epoch 49, global step 18900: 'val/ADE' was not in top 1
Epoch 50, global step 19278: 'val/ADE' was not in top 1
Epoch 51, global step 19656: 'val/ADE' was not in top 1
Epoch 52, global step 20034: 'val/ADE' was not in top 1
Monitored metric val/ADE did not improve in the last 20 records. Best score: 1.998. Signaling Trainer to stop.
Epoch 53, global step 20412: 'val/ADE' was not in top 1
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]
SLURM auto-requeueing enabled. Setting signal handlers.
wandb: - 331.028 MB of 331.028 MB uploadedwandb: \ 331.028 MB of 331.028 MB uploadedwandb: | 331.028 MB of 331.059 MB uploadedwandb: / 331.028 MB of 331.059 MB uploadedwandb: - 331.059 MB of 331.059 MB uploadedwandb: 
wandb: Run history:
wandb:   CPU energy consumption (kWh) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–‡â–
wandb:   GPU energy consumption (kWh) â–†â–†â–‡â–†â–†â–‡â–†â–†â–†â–†â–â–‡â–†â–†â–†â–†â–â–†â–‡â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–â–ˆâ–ˆâ–†â–†â–†â–â–†â–†â–†â–†â–†â–
wandb:   RAM energy consumption (kWh) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–†â–‡â–‡â–â–†â–†â–‡â–‡â–†â–
wandb: Total energy consumption (kWh) â–‡â–‡â–‡â–†â–†â–‡â–†â–†â–†â–†â–â–‡â–†â–†â–†â–†â–â–†â–‡â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–â–ˆâ–ˆâ–†â–†â–†â–â–†â–†â–†â–†â–†â–
wandb:                          epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:               train/loss_epoch â–ƒâ–‡â–‚â–‚â–‚â–„â–ƒâ–ƒâ–„â–…â–‚â–…â–ƒâ–„â–‚â–ƒâ–„â–„â–â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–‡â–ˆâ–„â–„â–‚â–ƒâ–…â–…â–ƒâ–„â–‚â–‚â–†â–‡
wandb:                train/loss_step â–…â–„â–‡â–ƒâ–†â–ƒâ–ƒâ–‚â–ƒâ–…â–„â–ƒâ–ƒâ–…â–„â–‚â–‚â–ˆâ–ƒâ–…â–…â–„â–†â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–â–„â–ƒâ–…â–‚â–„â–…â–„â–†â–ƒâ–„
wandb:            trainer/global_step â–â–â–â–‚â–â–â–‚â–‚â–ƒâ–â–â–ƒâ–ƒâ–ƒâ–„â–â–„â–„â–„â–„â–â–â–…â–…â–…â–â–â–†â–†â–†â–†â–â–‡â–‡â–‡â–‡â–â–â–ˆâ–
wandb:                  val/ADE_epoch â–‚â–†â–„â–…â–ˆâ–„â–†â–„â–ƒâ–ˆâ–„â–‚â–‡â–„â–…â–ƒâ–ƒâ–„â–…â–‡â–ƒâ–„â–†â–†â–â–‡â–ƒâ–ƒâ–‡â–‡â–„â–„â–†â–ƒâ–†â–†â–ƒâ–†â–†â–„
wandb:                   val/ADE_step â–„â–â–‚â–„â–ƒâ–„â–„â–ƒâ–â–ƒâ–ƒâ–â–ƒâ–ƒâ–…â–ƒâ–‚â–„â–„â–…â–†â–ƒâ–‡â–ˆâ–â–†â–…â–‚â–‚â–…â–â–ƒâ–ˆâ–„â–‚â–ƒâ–ƒâ–…â–ƒâ–„
wandb:                  val/FDE_epoch â–ƒâ–‡â–„â–†â–‡â–…â–†â–„â–ƒâ–‡â–„â–ƒâ–ˆâ–…â–…â–„â–„â–„â–…â–ˆâ–„â–†â–†â–†â–â–‡â–…â–„â–‡â–ˆâ–…â–…â–‡â–…â–…â–†â–ƒâ–‡â–†â–„
wandb:                   val/FDE_step â–„â–‚â–‚â–„â–…â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–†â–‚â–‚â–…â–„â–…â–ˆâ–„â–ˆâ–ˆâ–â–‡â–†â–ƒâ–‚â–‡â–‚â–ƒâ–ˆâ–„â–„â–ƒâ–‚â–…â–„â–„
wandb:               val/NL_ADE_epoch â–‚â–†â–„â–†â–†â–…â–‡â–†â–ƒâ–‡â–…â–„â–…â–…â–†â–‡â–„â–…â–…â–†â–…â–…â–‡â–†â–â–†â–„â–ƒâ–‡â–ˆâ–…â–ˆâ–‡â–ƒâ–†â–†â–ƒâ–†â–…â–…
wandb:                val/NL_ADE_step â–„â–‚â–ƒâ–…â–„â–ƒâ–„â–‚â–‚â–„â–ƒâ–ƒâ–â–‚â–ƒâ–„â–‚â–ƒâ–„â–„â–ƒâ–‚â–‡â–‡â–‚â–…â–ƒâ–‚â–ƒâ–ˆâ–â–ƒâ–‡â–„â–…â–…â–ƒâ–„â–ƒâ–
wandb: 
wandb: Run summary:
wandb:   CPU energy consumption (kWh) 0.0
wandb:   GPU energy consumption (kWh) 0.0
wandb:   RAM energy consumption (kWh) 0.0
wandb: Total energy consumption (kWh) 0.0
wandb:                          epoch 54
wandb:               train/loss_epoch 1.8479
wandb:                train/loss_step 2.22267
wandb:            trainer/global_step 20412
wandb:                  val/ADE_epoch 2.05885
wandb:                   val/ADE_step 2.08908
wandb:                  val/FDE_epoch 4.34464
wandb:                   val/FDE_step 4.46258
wandb:               val/NL_ADE_epoch 2.39238
wandb:                val/NL_ADE_step 2.67448
wandb: 
wandb: ğŸš€ View run uni_bitnet_NBA_train_50_100_nba_fine_tune at: https://wandb.ai/luffnis1/lightning_logs/runs/z5amb67l
wandb: â­ï¸ View project at: https://wandb.ai/luffnis1/lightning_logs
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240801_003527-z5amb67l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
