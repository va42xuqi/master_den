GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
wandb: Currently logged in as: luffnis (luffnis1). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in ./wandb/run-20240801_002049-8zohoypr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run oslmu_NBA_train_50_100_nba_fine_tune
wandb: ⭐️ View project at https://wandb.ai/luffnis1/lightning_logs
wandb: 🚀 View run at https://wandb.ai/luffnis1/lightning_logs/runs/8zohoypr
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]

  | Name          | Type   | Params
-----------------------------------------
0 | lmu           | LMU    | 152 K 
1 | preprocessing | LMU    | 90.5 K
2 | fc_out        | Linear | 51.4 K
-----------------------------------------
294 K     Trainable params
0         Non-trainable params
294 K     Total params
1.176     Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Metric val/ADE improved. New best score: 1.915
Epoch 0, global step 95: 'val/ADE' reached 1.91454 (best 1.91454), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/nba/oslmu_nba_fine_tune-v1.ckpt' as top 1
Epoch 1, global step 190: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.031 >= min_delta = 0.0. New best score: 1.883
Epoch 2, global step 285: 'val/ADE' reached 1.88346 (best 1.88346), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/nba/oslmu_nba_fine_tune-v1.ckpt' as top 1
Epoch 3, global step 380: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.027 >= min_delta = 0.0. New best score: 1.856
Epoch 4, global step 475: 'val/ADE' reached 1.85639 (best 1.85639), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/nba/oslmu_nba_fine_tune-v1.ckpt' as top 1
Epoch 5, global step 570: 'val/ADE' was not in top 1
Epoch 6, global step 665: 'val/ADE' was not in top 1
Epoch 7, global step 760: 'val/ADE' was not in top 1
Epoch 8, global step 855: 'val/ADE' was not in top 1
Epoch 9, global step 950: 'val/ADE' was not in top 1
Epoch 10, global step 1045: 'val/ADE' was not in top 1
Epoch 11, global step 1140: 'val/ADE' was not in top 1
Epoch 12, global step 1235: 'val/ADE' was not in top 1
Epoch 13, global step 1330: 'val/ADE' was not in top 1
Epoch 14, global step 1425: 'val/ADE' was not in top 1
Epoch 15, global step 1520: 'val/ADE' was not in top 1
Epoch 16, global step 1615: 'val/ADE' was not in top 1
Epoch 17, global step 1710: 'val/ADE' was not in top 1
Epoch 18, global step 1805: 'val/ADE' was not in top 1
Epoch 19, global step 1900: 'val/ADE' was not in top 1
Epoch 20, global step 1995: 'val/ADE' was not in top 1
Epoch 21, global step 2090: 'val/ADE' was not in top 1
Epoch 22, global step 2185: 'val/ADE' was not in top 1
Epoch 23, global step 2280: 'val/ADE' was not in top 1
Monitored metric val/ADE did not improve in the last 20 records. Best score: 1.856. Signaling Trainer to stop.
Epoch 24, global step 2375: 'val/ADE' was not in top 1
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
SLURM auto-requeueing enabled. Setting signal handlers.
wandb: - 10.171 MB of 10.171 MB uploadedwandb: \ 10.173 MB of 10.201 MB uploadedwandb: | 10.197 MB of 10.201 MB uploadedwandb: / 10.197 MB of 10.201 MB uploadedwandb: - 10.201 MB of 10.201 MB uploadedwandb: 
wandb: Run history:
wandb:   CPU energy consumption (kWh) ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁
wandb:   GPU energy consumption (kWh) ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁
wandb:   RAM energy consumption (kWh) ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁
wandb: Total energy consumption (kWh) ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁
wandb:                          epoch ▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██
wandb:               train/loss_epoch ▇▅▆▂▆▅▅▅█▃▃▆▅▂▁▄▅▅▄▄▄▁▃▂▅
wandb:                train/loss_step ▆▂▂▅▄▂▅▃▄▃▄▃▃▅▄▃▅▁▃▂▁▄▃▆▄█▃▆▂▆▂▄▂▃▃▂▁▂▄▄
wandb:            trainer/global_step ▁▁▁▂▁▂▁▁▃▁▃▃▁▃▄▁▄▄▁▅▁▅▅▁▅▆▁▆▆▁▇▁▁▇▁▇█▁█▁
wandb:                  val/ADE_epoch ▅▆▃▃▁█▃▄▄▃▃▃▆▄▃▇▇▃▄▆▂▂▅▅▇█
wandb:                   val/ADE_step ▆▅▃▅▅▁▅▃▁▇▅▂▅▃▅▅▄▄▇▄▄▅▅▅▅▅▅▅▆▅▅▄▄▅▅▄▇█▆▅
wandb:                  val/FDE_epoch ▄▃▂▄▂█▃▂▅▁▄▃█▄▂▅▆▂▅▄▂▃▅▆█▇
wandb:                   val/FDE_step ▆▅▂▃▃▁▆▃▁▆▄▁▄▃▅▄▄▅▇▄▅▄▄▅▃▅▅▄▆▅▄▅▅▅▅▅▇█▅▄
wandb:               val/NL_ADE_epoch ▅▅▆▃▃▆▅▄▁▃▆▃▄▄▅▇▅▄▂▆▆▅▇▄▅█
wandb:                val/NL_ADE_step ▆▄▃▅▄▃▄▄▁▆▆▂▄▂▅▆▅▇▅▃▅▇▅▆▅▅▄▇▇▄▅▅▅█▆▇▅█▆█
wandb: 
wandb: Run summary:
wandb:   CPU energy consumption (kWh) 5e-05
wandb:   GPU energy consumption (kWh) 0.00028
wandb:   RAM energy consumption (kWh) 0.0
wandb: Total energy consumption (kWh) 0.00034
wandb:                          epoch 25
wandb:               train/loss_epoch 1.70168
wandb:                train/loss_step 1.66586
wandb:            trainer/global_step 2375
wandb:                  val/ADE_epoch 1.97043
wandb:                   val/ADE_step 1.95169
wandb:                  val/FDE_epoch 4.14262
wandb:                   val/FDE_step 4.09523
wandb:               val/NL_ADE_epoch 2.30125
wandb:                val/NL_ADE_step 2.41898
wandb: 
wandb: 🚀 View run oslmu_NBA_train_50_100_nba_fine_tune at: https://wandb.ai/luffnis1/lightning_logs/runs/8zohoypr
wandb: ⭐️ View project at: https://wandb.ai/luffnis1/lightning_logs
wandb: Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240801_002049-8zohoypr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
