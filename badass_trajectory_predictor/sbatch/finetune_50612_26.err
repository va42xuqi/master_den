GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
wandb: Currently logged in as: luffnis (luffnis1). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in ./wandb/run-20240727_061127-jdxif5l8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run two_layer_linear_SOC_train_50_100
wandb: ⭐️ View project at https://wandb.ai/luffnis1/lightning_logs
wandb: 🚀 View run at https://wandb.ai/luffnis1/lightning_logs/runs/jdxif5l8
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name          | Type    | Params
------------------------------------------
0 | linear        | Linear  | 820 K 
1 | non_linearity | GELU    | 0     
2 | dropout       | Dropout | 0     
3 | linear2       | Linear  | 205 K 
------------------------------------------
1.0 M     Trainable params
0         Non-trainable params
1.0 M     Total params
4.101     Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Metric val/ADE improved. New best score: 2.097
Epoch 0, global step 95: 'val/ADE' reached 2.09742 (best 2.09742), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/two_layer_linear_nba_fine_tune.ckpt' as top 1
Epoch 1, global step 190: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.016 >= min_delta = 0.0. New best score: 2.081
Epoch 2, global step 285: 'val/ADE' reached 2.08125 (best 2.08125), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/two_layer_linear_nba_fine_tune.ckpt' as top 1
Epoch 3, global step 380: 'val/ADE' was not in top 1
Epoch 4, global step 475: 'val/ADE' was not in top 1
Epoch 5, global step 570: 'val/ADE' was not in top 1
Epoch 6, global step 665: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.011 >= min_delta = 0.0. New best score: 2.071
Epoch 7, global step 760: 'val/ADE' reached 2.07070 (best 2.07070), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/two_layer_linear_nba_fine_tune.ckpt' as top 1
Metric val/ADE improved by 0.003 >= min_delta = 0.0. New best score: 2.068
Epoch 8, global step 855: 'val/ADE' reached 2.06816 (best 2.06816), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/two_layer_linear_nba_fine_tune.ckpt' as top 1
Epoch 9, global step 950: 'val/ADE' was not in top 1
Epoch 10, global step 1045: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.023 >= min_delta = 0.0. New best score: 2.045
Epoch 11, global step 1140: 'val/ADE' reached 2.04534 (best 2.04534), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/two_layer_linear_nba_fine_tune.ckpt' as top 1
Epoch 12, global step 1235: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.017 >= min_delta = 0.0. New best score: 2.028
Epoch 13, global step 1330: 'val/ADE' reached 2.02792 (best 2.02792), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/two_layer_linear_nba_fine_tune.ckpt' as top 1
Metric val/ADE improved by 0.020 >= min_delta = 0.0. New best score: 2.008
Epoch 14, global step 1425: 'val/ADE' reached 2.00755 (best 2.00755), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/two_layer_linear_nba_fine_tune.ckpt' as top 1
Epoch 15, global step 1520: 'val/ADE' was not in top 1
Epoch 16, global step 1615: 'val/ADE' was not in top 1
Epoch 17, global step 1710: 'val/ADE' was not in top 1
Epoch 18, global step 1805: 'val/ADE' was not in top 1
Epoch 19, global step 1900: 'val/ADE' was not in top 1
Epoch 20, global step 1995: 'val/ADE' was not in top 1
Epoch 21, global step 2090: 'val/ADE' was not in top 1
Epoch 22, global step 2185: 'val/ADE' was not in top 1
Epoch 23, global step 2280: 'val/ADE' was not in top 1
Epoch 24, global step 2375: 'val/ADE' was not in top 1
Epoch 25, global step 2470: 'val/ADE' was not in top 1
Epoch 26, global step 2565: 'val/ADE' was not in top 1
Epoch 27, global step 2660: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.043 >= min_delta = 0.0. New best score: 1.965
Epoch 28, global step 2755: 'val/ADE' reached 1.96482 (best 1.96482), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/two_layer_linear_nba_fine_tune.ckpt' as top 1
Epoch 29, global step 2850: 'val/ADE' was not in top 1
Epoch 30, global step 2945: 'val/ADE' was not in top 1
Epoch 31, global step 3040: 'val/ADE' was not in top 1
Epoch 32, global step 3135: 'val/ADE' was not in top 1
Epoch 33, global step 3230: 'val/ADE' was not in top 1
Epoch 34, global step 3325: 'val/ADE' was not in top 1
Epoch 35, global step 3420: 'val/ADE' was not in top 1
Epoch 36, global step 3515: 'val/ADE' was not in top 1
Epoch 37, global step 3610: 'val/ADE' was not in top 1
Epoch 38, global step 3705: 'val/ADE' was not in top 1
Epoch 39, global step 3800: 'val/ADE' was not in top 1
Epoch 40, global step 3895: 'val/ADE' was not in top 1
Epoch 41, global step 3990: 'val/ADE' was not in top 1
Epoch 42, global step 4085: 'val/ADE' was not in top 1
Epoch 43, global step 4180: 'val/ADE' was not in top 1
Epoch 44, global step 4275: 'val/ADE' was not in top 1
Epoch 45, global step 4370: 'val/ADE' was not in top 1
Epoch 46, global step 4465: 'val/ADE' was not in top 1
Epoch 47, global step 4560: 'val/ADE' was not in top 1
Monitored metric val/ADE did not improve in the last 20 records. Best score: 1.965. Signaling Trainer to stop.
Epoch 48, global step 4655: 'val/ADE' was not in top 1
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
SLURM auto-requeueing enabled. Setting signal handlers.
wandb: - 93.926 MB of 93.926 MB uploadedwandb: \ 93.927 MB of 93.957 MB uploadedwandb: | 93.957 MB of 93.957 MB uploadedwandb: 
wandb: Run history:
wandb:   CPU energy consumption (kWh) ▆█▇▆▆▁▆▇▇▆▆▁▆▆▆▆▆▆▆▆▆▆▇▆▁▆▆▆▆▆▁▇▆▆▆▆▁▆▆▆
wandb:   GPU energy consumption (kWh) ▆█▇▆▇▁▆▇▆▆▆▁▆▆▅▆▇▇▆▆▆▆▆▆▁▅▇▇▆▆▁▇▆▆▆▆▁▆▇▆
wandb:   RAM energy consumption (kWh) ▆█▆▆▆▁▆▆▆▆▆▁▆▆▆▆▆▆▆▆▆▆▇▆▁▆▆▆▆▆▁▇▆▆▆▆▁▆▆▆
wandb: Total energy consumption (kWh) ▆█▇▆▇▁▆▇▆▆▆▁▆▆▆▆▇▇▆▆▆▆▆▆▁▆▇▇▆▆▁▇▆▆▆▆▁▆▆▆
wandb:                          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███
wandb:               train/loss_epoch █▄▄▃▃▃▃▃▂▂▂▁▃▁▁▂▂▂▂▂▁▂▁▂▂▂▂▂▃▂▂▁▁▂▂▂▂▁▁▁
wandb:                train/loss_step ▅▄▆█▆▆█▆▆▇▆▄▅▄▄▇▇▆▆▆▅▄▄▅▆█▇▅█▄█▄▇▁▄▇▇▇▆▇
wandb:            trainer/global_step ▁▁▁▁▂▂▁▁▂▁▁▃▃▃▄▄▄▄▁▁▅▅▁▁▅▆▆▆▆▆▆▁▇▇▁▁▇███
wandb:                  val/ADE_epoch ▅█▅▆▆▆▅▄▅▄▄▃▄▃▃▄▅▄▄▄▆▅▄▁▄▂▄▄▂▂▃▃▇▂▂▂▄▃▂▅
wandb:                   val/ADE_step ▆▃▅█▅█▅▅▇▁▄▅▂▃▄▄▇▅▄▅▃▃▅▂▆▄▄▄▄▄▄▁▆▅▁▄▅▄▅▃
wandb:                  val/FDE_epoch ▆█▅▇▆▇▄▅▅▄▄▄▃▄▃▅▇▄▅▅▇▆▄▁▆▃▄▆▃▄▄▅▇▃▃▂▆▃▃▅
wandb:                   val/FDE_step ▆▃▄▇▅█▄▅▇▁▃▅▂▃▄▃▇▅▄▅▃▃▄▃▅▄▅▄▄▅▅▂▅▅▁▃▅▄▅▃
wandb:               val/NL_ADE_epoch █▇▇▇▄▆▅▅▅▃▄▁▆▂▄▄▃▄▃▃▅▆▄▄▅▃▅▄▄▄▃▂▆▂▃▄▃▄▄▆
wandb:                val/NL_ADE_step ▆▂▃█▃▇▅▄▅▁▃▂▃▂▅▃▆▂▂▆▂▁▃▂▄▅▁▃▄▄▄▁▄▃▁▃▂▄▆▂
wandb: 
wandb: Run summary:
wandb:   CPU energy consumption (kWh) 1e-05
wandb:   GPU energy consumption (kWh) 4e-05
wandb:   RAM energy consumption (kWh) 0.0
wandb: Total energy consumption (kWh) 5e-05
wandb:                          epoch 49
wandb:               train/loss_epoch 1.8055
wandb:                train/loss_step 1.74448
wandb:            trainer/global_step 4655
wandb:                  val/ADE_epoch 2.08178
wandb:                   val/ADE_step 2.12524
wandb:                  val/FDE_epoch 4.30299
wandb:                   val/FDE_step 4.4037
wandb:               val/NL_ADE_epoch 2.39686
wandb:                val/NL_ADE_step 2.58231
wandb: 
wandb: 🚀 View run two_layer_linear_SOC_train_50_100 at: https://wandb.ai/luffnis1/lightning_logs/runs/jdxif5l8
wandb: ⭐️ View project at: https://wandb.ai/luffnis1/lightning_logs
wandb: Synced 6 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240727_061127-jdxif5l8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
