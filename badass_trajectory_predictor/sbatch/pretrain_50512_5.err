GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
wandb: Currently logged in as: luffnis (luffnis1). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in ./wandb/run-20240726_163206-lmdt5gjr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run os_bitnet_SOC_train_50_100
wandb: â­ï¸ View project at https://wandb.ai/luffnis1/lightning_logs
wandb: ğŸš€ View run at https://wandb.ai/luffnis1/lightning_logs/runs/lmdt5gjr
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]

  | Name    | Type       | Params
---------------------------------------
0 | linear  | Linear     | 26.9 K
1 | encoder | GPTLike    | 4.8 M 
2 | cnn     | CNNEncoder | 12.5 K
3 | fc_out  | Linear     | 51.4 K
4 | dropout | Dropout    | 0     
---------------------------------------
4.9 M     Trainable params
0         Non-trainable params
4.9 M     Total params
19.430    Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.5 seconds.), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.2 seconds.), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.1 seconds.), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.7 seconds.), retrying request
Metric val/ADE improved. New best score: 3.352
Epoch 0, global step 331: 'val/ADE' reached 3.35237 (best 3.35237), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/os_bitnet_pretrain.ckpt' as top 1
Epoch 1, global step 662: 'val/ADE' was not in top 1
Epoch 2, global step 993: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.089 >= min_delta = 0.0. New best score: 3.263
Epoch 3, global step 1324: 'val/ADE' reached 3.26293 (best 3.26293), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/os_bitnet_pretrain.ckpt' as top 1
Metric val/ADE improved by 0.157 >= min_delta = 0.0. New best score: 3.106
Epoch 4, global step 1655: 'val/ADE' reached 3.10604 (best 3.10604), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/os_bitnet_pretrain.ckpt' as top 1
Epoch 5, global step 1986: 'val/ADE' was not in top 1
Epoch 6, global step 2317: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.047 >= min_delta = 0.0. New best score: 3.059
Epoch 7, global step 2648: 'val/ADE' reached 3.05921 (best 3.05921), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/os_bitnet_pretrain.ckpt' as top 1
Epoch 8, global step 2979: 'val/ADE' was not in top 1
Epoch 9, global step 3310: 'val/ADE' was not in top 1
Epoch 10, global step 3641: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.054 >= min_delta = 0.0. New best score: 3.005
Epoch 11, global step 3972: 'val/ADE' reached 3.00514 (best 3.00514), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/os_bitnet_pretrain.ckpt' as top 1
Epoch 12, global step 4303: 'val/ADE' was not in top 1
Epoch 13, global step 4634: 'val/ADE' was not in top 1
Epoch 14, global step 4965: 'val/ADE' was not in top 1
Epoch 15, global step 5296: 'val/ADE' was not in top 1
Epoch 16, global step 5627: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.036 >= min_delta = 0.0. New best score: 2.969
Epoch 17, global step 5958: 'val/ADE' reached 2.96921 (best 2.96921), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/os_bitnet_pretrain.ckpt' as top 1
Epoch 18, global step 6289: 'val/ADE' was not in top 1
Epoch 19, global step 6620: 'val/ADE' was not in top 1
Epoch 20, global step 6951: 'val/ADE' was not in top 1
Metric val/ADE improved by 0.204 >= min_delta = 0.0. New best score: 2.765
Epoch 21, global step 7282: 'val/ADE' reached 2.76514 (best 2.76514), saving model to '/data/beegfs/home/gosalcds/master_den/badass_trajectory_predictor/checkpoints/soc/os_bitnet_pretrain.ckpt' as top 1
Epoch 22, global step 7613: 'val/ADE' was not in top 1
Epoch 23, global step 7944: 'val/ADE' was not in top 1
Epoch 24, global step 8275: 'val/ADE' was not in top 1
Epoch 25, global step 8606: 'val/ADE' was not in top 1
Epoch 26, global step 8937: 'val/ADE' was not in top 1
Epoch 27, global step 9268: 'val/ADE' was not in top 1
Epoch 28, global step 9599: 'val/ADE' was not in top 1
Epoch 29, global step 9930: 'val/ADE' was not in top 1
Epoch 30, global step 10261: 'val/ADE' was not in top 1
Epoch 31, global step 10592: 'val/ADE' was not in top 1
Epoch 32, global step 10923: 'val/ADE' was not in top 1
Epoch 33, global step 11254: 'val/ADE' was not in top 1
Epoch 34, global step 11585: 'val/ADE' was not in top 1
Epoch 35, global step 11916: 'val/ADE' was not in top 1
Epoch 36, global step 12247: 'val/ADE' was not in top 1
Epoch 37, global step 12578: 'val/ADE' was not in top 1
Epoch 38, global step 12909: 'val/ADE' was not in top 1
Epoch 39, global step 13240: 'val/ADE' was not in top 1
Epoch 40, global step 13571: 'val/ADE' was not in top 1
Monitored metric val/ADE did not improve in the last 20 records. Best score: 2.765. Signaling Trainer to stop.
Epoch 41, global step 13902: 'val/ADE' was not in top 1
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
SLURM auto-requeueing enabled. Setting signal handlers.
wandb: - 389.113 MB of 389.113 MB uploadedwandb: \ 389.113 MB of 389.113 MB uploadedwandb: | 389.113 MB of 389.144 MB uploadedwandb: / 389.144 MB of 389.144 MB uploadedwandb: 
wandb: Run history:
wandb:   CPU energy consumption (kWh) â–ˆâ–ˆâ–‡â–†â–‡â–‡â–â–‡â–‡â–†â–†â–†â–‡â–â–‡â–‡â–‡â–‡â–‡â–†â–â–‡â–‡â–†â–†â–‡â–‡â–†â–â–ˆâ–‡â–†â–ˆâ–‡â–‡â–â–†â–†â–‡â–…
wandb:   GPU energy consumption (kWh) â–…â–…â–‡â–‡â–‡â–‡â–â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–â–ˆâ–…â–„â–…â–†â–†â–â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–…â–â–…â–…â–…â–…
wandb:   RAM energy consumption (kWh) â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–â–ˆâ–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–†â–‡â–ˆâ–‡â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–â–‡â–‡â–‡â–†
wandb: Total energy consumption (kWh) â–†â–†â–‡â–‡â–‡â–‡â–â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–â–ˆâ–†â–…â–…â–†â–†â–â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–â–‡â–‡â–ˆâ–ˆâ–ˆâ–†â–â–…â–†â–†â–…
wandb:                          epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:               train/loss_epoch â–ˆâ–‡â–‡â–†â–†â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                train/loss_step â–ƒâ–†â–…â–†â–„â–†â–…â–ƒâ–†â–‚â–ƒâ–„â–ƒâ–…â–ˆâ–…â–ƒâ–„â–„â–…â–ƒâ–„â–ƒâ–ƒâ–…â–„â–â–…â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–„â–„â–ƒâ–„â–‚â–…
wandb:            trainer/global_step â–â–â–â–‚â–â–‚â–â–â–ƒâ–â–â–ƒâ–ƒâ–„â–„â–„â–„â–â–„â–…â–â–â–…â–â–â–†â–†â–â–†â–†â–‡â–‡â–‡â–‡â–â–‡â–ˆâ–â–ˆâ–
wandb:                  val/ADE_epoch â–‡â–ˆâ–‡â–†â–…â–†â–†â–„â–…â–…â–„â–ƒâ–„â–„â–„â–„â–ƒâ–„â–„â–„â–â–ƒâ–„â–„â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–â–ƒâ–„â–…â–‚â–‚â–ƒâ–‚â–
wandb:                   val/ADE_step â–†â–„â–†â–‡â–„â–‡â–„â–†â–„â–†â–ƒâ–„â–„â–„â–…â–‚â–â–„â–…â–…â–ƒâ–ƒâ–…â–ƒâ–‚â–„â–„â–„â–„â–ƒâ–„â–‚â–‚â–ˆâ–…â–„â–ƒâ–‚â–â–‚
wandb:                  val/FDE_epoch â–‡â–ˆâ–‡â–†â–…â–‡â–‡â–„â–†â–…â–…â–„â–„â–ƒâ–„â–„â–ƒâ–„â–„â–„â–â–„â–„â–…â–ƒâ–ƒâ–„â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–…â–†â–‚â–‚â–„â–ƒâ–‚
wandb:                   val/FDE_step â–…â–ƒâ–…â–‡â–„â–‡â–„â–…â–„â–†â–ƒâ–„â–„â–ƒâ–…â–â–‚â–…â–†â–…â–ƒâ–ƒâ–†â–ƒâ–ƒâ–„â–„â–„â–„â–ƒâ–„â–ƒâ–‚â–ˆâ–„â–„â–ƒâ–‚â–‚â–‚
wandb:               val/NL_ADE_epoch â–‡â–ˆâ–‡â–…â–„â–†â–…â–„â–…â–…â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–â–‚â–„â–„â–‚â–‚â–‚â–‚â–
wandb:                val/NL_ADE_step â–‡â–…â–‡â–ˆâ–…â–ˆâ–…â–‡â–„â–‡â–ƒâ–„â–„â–„â–…â–â–â–…â–†â–…â–ƒâ–„â–…â–ƒâ–ƒâ–„â–„â–„â–…â–„â–…â–‚â–â–ˆâ–†â–…â–„â–â–â–‚
wandb: 
wandb: Run summary:
wandb:   CPU energy consumption (kWh) 5e-05
wandb:   GPU energy consumption (kWh) 0.00022
wandb:   RAM energy consumption (kWh) 0.0
wandb: Total energy consumption (kWh) 0.00027
wandb:                          epoch 42
wandb:               train/loss_epoch 1.74786
wandb:                train/loss_step 2.76444
wandb:            trainer/global_step 13902
wandb:                  val/ADE_epoch 2.80112
wandb:                   val/ADE_step 2.98553
wandb:                  val/FDE_epoch 5.58492
wandb:                   val/FDE_step 6.20358
wandb:               val/NL_ADE_epoch 2.91904
wandb:                val/NL_ADE_step 3.4414
wandb: 
wandb: ğŸš€ View run os_bitnet_SOC_train_50_100 at: https://wandb.ai/luffnis1/lightning_logs/runs/lmdt5gjr
wandb: â­ï¸ View project at: https://wandb.ai/luffnis1/lightning_logs
wandb: Synced 6 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240726_163206-lmdt5gjr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
